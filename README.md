# ğŸ§  MNEME â€“ Motor de Memoria Neural MÃ³rfica

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch 2.0+](https://img.shields.io/badge/PyTorch-2.0+-ee4c2c.svg)](https://pytorch.org/)
[![License: BUSL-1.1](https://img.shields.io/badge/License-BUSL--1.1-blue.svg)](https://opensource.org/licenses/BUSL-1.1)
[![Security](https://img.shields.io/badge/Security-Enterprise-green.svg)](https://github.com/esraderey/MNEME---Motor-de-Memoria-Neural-M-rfica)
[![Performance](https://img.shields.io/badge/Performance-Optimized-orange.svg)](https://github.com/esraderey/MNEME---Motor-de-Memoria-Neural-M-rfica)

**MNEME** (pronunciado *"neme"*) redefine la memoria computacional mediante un motor neural inspirado en estructuras biolÃ³gicas.  
En lugar de almacenar datos en ubicaciones fijas, **MNEME guarda descriptores compactos y generativos** que reconstruyen el contenido de forma determinista, como si fueran recuerdos que emergen bajo demanda.

---

## ğŸ“‹ Nombre del Proyecto

**MNEME**

- **M**emoria  
- **N**eural  
- **E**structurada  
- **M**Ã³rfica  
- **E**mergente  

---

## ğŸš€ InnovaciÃ³n Clave

Tradicional: **DirecciÃ³n â†’ LocalizaciÃ³n â†’ Datos**  
MNEME: **Descriptor â†’ SÃ­ntesis â†’ Recuerdo**

```python
# Tradicional: Guardar tensor de 4MB en RAM
memory[0x1000] = huge_tensor  

# MNEME: Guardar descriptor de 40KB
descriptor = mneme.store(huge_tensor)  
tensor = mneme.synthesize(descriptor)  # ReconstrucciÃ³n determinista
```

## ğŸ¯ Â¿Por quÃ© MNEME?

ğŸ”¹ **10â€“100x reducciÃ³n de memoria** para modelos ML, imÃ¡genes y estados de simulaciÃ³n

ğŸ”¹ **SÃ­ntesis determinista** â€“ mismo descriptor, mismo resultado garantizado

ğŸ”¹ **VerificaciÃ³n criptogrÃ¡fica de extremo a extremo** â€“ autenticidad e integridad con firmado HMAC en cada operaciÃ³n

ğŸ”¹ **Control de versiones optimizado** â€“ seguimiento eficiente con cadenas de deltas y consolidaciÃ³n automÃ¡tica

ğŸ”¹ **Eficiencia energÃ©tica** â€“ minimiza el movimiento de datos siguiendo el principio de Landauer

ğŸ”¹ **Seguridad empresarial** â€“ firmado HMAC, checksums robustos y arquitectura segura por defecto

ğŸ”¹ **OptimizaciÃ³n automÃ¡tica** â€“ gestiÃ³n inteligente de memoria (CPU/GPU) y rendimiento sostenido

## ğŸ“Š MÃ©tricas de Rendimiento

| MÃ©trica | Rendimiento |
|---------|-------------|
| Ratio de compresiÃ³n | 10â€“20x en transformadores |
| Latencia de sÃ­ntesis | <150Î¼s (tiles de 256KB) |
| Latencia de cachÃ© (CPU) | <1Î¼s |
| PÃ©rdida de calidad | <1% en inferencia ML |
| Ahorro de memoria VRAM | >90% con cachÃ© en CPU |
| VerificaciÃ³n HMAC | <10Î¼s por operaciÃ³n |
| Throughput paralelo | 8x aceleraciÃ³n con 8 cores |

<details>
<summary><b>ğŸ“Š Exportar a Hojas de cÃ¡lculo</b></summary>

Puedes copiar la siguiente tabla para importar en Excel, Google Sheets o cualquier aplicaciÃ³n de hojas de cÃ¡lculo:

```
MÃ©trica	Rendimiento
Ratio de compresiÃ³n	10â€“20x en transformadores
Latencia de sÃ­ntesis	<150Î¼s (tiles de 256KB)
Latencia de cachÃ© (CPU)	<1Î¼s
PÃ©rdida de calidad	<1% en inferencia ML
Ahorro de memoria VRAM	>90% con cachÃ© en CPU
VerificaciÃ³n HMAC	<10Î¼s por operaciÃ³n
Throughput paralelo	8x aceleraciÃ³n con 8 cores
```

</details>

## ğŸ› ï¸ InstalaciÃ³n

### Requisitos

- Python 3.8+
- PyTorch 2.0+
- RAM: mÃ­nimo 4GB (recomendado 8GB)
- Linux / macOS / Windows

### InstalaciÃ³n bÃ¡sica

```bash
pip install mneme
```

### InstalaciÃ³n completa con todas las funcionalidades

```bash
git clone https://github.com/esraderey/MNEME---Motor-de-Memoria-Neural-M-rfica.git
cd MNEME---Motor-de-Memoria-Neural-M-rfica
pip install -r requirements.txt
pip install -e .[all]
```

### InstalaciÃ³n con optimizaciones

```bash
# Para desarrollo
pip install -e .[dev]

# Para GPU
pip install -e .[gpu]

# Para seguridad empresarial
pip install -e .[security]

# Para optimizaciÃ³n mÃ¡xima
pip install -e .[optimization]
```

## ğŸš¦ Uso RÃ¡pido

### Guardar y recuperar con configuraciÃ³n centralizada

```python
import torch
import secrets
from mneme_core import ZSpace, MnemeConfig, CompressionLevel

# 1. Configurar el motor de forma centralizada
config = MnemeConfig(
    cache_size_bytes=1 << 30,  # 1GB
    compression_level=CompressionLevel.HIGH,
    secret_key=secrets.token_bytes(32) # Clave para firmado HMAC
)

# 2. Usar como gestor de contexto para limpieza automÃ¡tica
with ZSpace(config) as mneme:
    tensor = torch.randn(1024, 1024)
    desc = mneme.register("mi_tensor", tensor, target_ratio=0.1)

    # Recuperar de forma segura y verificada
    loaded = mneme.load("mi_tensor")
    assert torch.allclose(tensor, loaded, rtol=1e-5)
```

### CompresiÃ³n de modelos PyTorch

```python
import torch.nn as nn
from mneme_torch import compress_model, get_compression_stats, CompressionConfig

# ConfiguraciÃ³n de compresiÃ³n
config = CompressionConfig(
    target_ratio=0.1,
    compression_level=CompressionLevel.HIGH,
    memory_limit=50 * 1024 * 1024  # 50MB
)

model = nn.Sequential(
    nn.Linear(784, 512), nn.ReLU(),
    nn.Linear(512, 256), nn.ReLU(),
    nn.Linear(256, 10)
)

compressed = compress_model(model, config=config)
stats = get_compression_stats(compressed)
print(f"CompresiÃ³n lograda: {stats['overall_ratio']:.1%}")
```

### Capas MNEME transparentes

```python
from mneme_torch import ZLinear, ZConv2d, ZAttention, ZTransformerBlock

# Reemplazo directo de capas PyTorch
model = nn.Sequential(
    ZLinear(784, 512, config=CompressionConfig(target_ratio=0.1)),
    nn.ReLU(),
    ZLinear(512, 256, config=CompressionConfig(target_ratio=0.05)),
    nn.ReLU(),
    ZLinear(256, 10, config=CompressionConfig(target_ratio=0.2))
)

# Transformer con compresiÃ³n
transformer = ZTransformerBlock(
    embed_dim=512, 
    num_heads=8, 
    config=CompressionConfig(target_ratio=0.1)
)
```

### Seguridad empresarial

```python
from mneme_security import SecurityManager, SecurityLevel

# Configurar seguridad
security_manager = SecurityManager(
    security_level=SecurityLevel.HIGH,
    audit_log_file="mneme_audit.log"
)

# Crear descriptor seguro
data = torch.randn(100, 100).numpy().tobytes()
secure_desc = security_manager.create_secure_descriptor(data, "sensitive_data")

# Verificar integridad
integrity_ok = secure_desc.verify_integrity()
signature_ok = secure_desc.verify_signature()
```

### OptimizaciÃ³n de rendimiento

```python
from mneme_optimization import MNEMEOptimizer, OptimizationLevel

# Configurar optimizador
optimizer = MNEMEOptimizer(
    max_memory_mb=1024,
    optimization_level=OptimizationLevel.MAXIMUM,
    enable_profiling=True,
    enable_parallel_processing=True
)

# Optimizar operaciones
tensors = [torch.randn(100, 100) for _ in range(10)]
optimized = optimizer.optimize_tensor_operations(tensors)

# Obtener reporte de rendimiento
report = optimizer.get_optimization_report()
```

## ğŸ—ï¸ Arquitectura Avanzada

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          MNEME Core V2                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Z-Addr (Hashing)   â”‚   Z-Gen (Synthesis)   â”‚   Security (HMAC) â”‚
â”‚  Cache (CPU-Aware)  â”‚   Proof (Merkle)      â”‚   Serializer      â”‚
â”‚  Prefetch (Markov)  â”‚   Delta Consolidation â”‚   Crypto Engine   â”‚
â”‚-----------------------------------------------------------------â”‚
â”‚   Motores de DescomposiciÃ³n: TT | CP | Tucker | SVD | Quantized   â”‚
â”‚   + CompresiÃ³n (LZ4) + Firmado HMAC + SerializaciÃ³n Segura      â”‚
â”‚   + GestiÃ³n de Memoria (CPU/GPU) + Procesamiento Paralelo       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Flujo de datos mejorado

**Store** â†’ Tensor â†’ Analyze â†’ Decompose â†’ Serialize â†’ Sign (HMAC) â†’ Compress â†’ Descriptor

**Load** â†’ Descriptor â†’ Decompress â†’ Verify (HMAC) â†’ Deserialize â†’ Reconstruct â†’ Verify â†’ Tensor

**Update** â†’ Delta â†’ Compress â†’ Append chain â†’ New version â†’ Consolidate (if needed)

**Security** â†’ Verify Signature â†’ Verify Checksum â†’ Audit â†’ Monitor

## ğŸ“ˆ Benchmarks Avanzados

### CompresiÃ³n de Modelos

**Transformer de 6 capas (GPT-2 Small)**
- ParÃ¡metros base: 6,299,648
- MNEME: 503,971 (12.5x compresiÃ³n)
- Uso de memoria: â€“91%
- PÃ©rdida de precisiÃ³n: <0.5%
- Tiempo de inferencia: +15% (aceptable)

**ResNet-50**
- ParÃ¡metros base: 25,557,032
- MNEME: 2,555,703 (10x compresiÃ³n)
- Uso de memoria VRAM: â€“90%
- PÃ©rdida de precisiÃ³n: <0.3%

### Rendimiento de Seguridad

- VerificaciÃ³n HMAC: <10Î¼s
- VerificaciÃ³n Merkle: <50Î¼s
- AuditorÃ­a de eventos: <1Î¼s
- Cifrado/descifrado: <100Î¼s

## ğŸ”¬ Funcionalidades Avanzadas

### ğŸ§  **NÃºcleo Inteligente**
- SelecciÃ³n automÃ¡tica de descomposiciÃ³n basada en propiedades del tensor
- Prefetching adaptativo con aprendizaje Markov de 2do orden
- GestiÃ³n de memoria CPU/GPU para preservar VRAM
- ConsolidaciÃ³n automÃ¡tica de deltas para un rendimiento sostenido
- Procesamiento paralelo para operaciones masivas

### ğŸ”’ **Seguridad Empresarial**
- VerificaciÃ³n de autenticidad e integridad con firmado HMAC-SHA256
- SerializaciÃ³n segura que previene ataques de ejecuciÃ³n de cÃ³digo
- Ãrboles Merkle para pruebas de integridad de datos fragmentados
- Arquitectura segura por defecto con generaciÃ³n de claves transitorias
- MÃºltiples niveles de seguridad (BASIC â†’ MAXIMUM)

### âš¡ **OptimizaciÃ³n de Rendimiento**
- Profiler integrado con mÃ©tricas detalladas
- GestiÃ³n automÃ¡tica de memoria y GC
- CachÃ© optimizado con polÃ­ticas LRU y monitoreo de presiÃ³n del sistema
- OptimizaciÃ³n de tensores con mÃºltiples niveles
- Monitoreo en tiempo real de recursos

### ğŸ”— **IntegraciÃ³n PyTorch**
- Drop-in replacement para capas estÃ¡ndar
- CompresiÃ³n transparente de modelos existentes
- Soporte completo para Transformer, CNN, RNN
- ConfiguraciÃ³n flexible por capa
- EstadÃ­sticas de rendimiento en tiempo real

## ğŸ® Aplicaciones

### **Machine Learning**
- CompresiÃ³n y serving de modelos LLM
- Entrenamiento distribuido eficiente
- Inferencia en dispositivos edge
- OptimizaciÃ³n de memoria en GPU

### **Simulaciones y Juegos**
- Mundos de juego infinitos y ligeros
- Estados de simulaciÃ³n masivos
- FÃ­sica en tiempo real
- Procedural generation

### **Ciencia de Datos**
- AnÃ¡lisis de datasets masivos
- CompresiÃ³n de matrices dispersas
- CÃ¡lculos cientÃ­ficos optimizados
- VisualizaciÃ³n de datos grandes

### **Seguridad y AuditorÃ­a**
- Sistemas de logging seguros
- VerificaciÃ³n de integridad
- Trazabilidad de datos
- Compliance empresarial

## ğŸ—ºï¸ Roadmap

### âœ… **Fase 1 â€“ NÃºcleo Completo**
- [x] DescomposiciÃ³n avanzada (TT, CP, Tucker, SVD, Quantized)
- [x] IntegraciÃ³n completa con PyTorch
- [x] Sistema de versiones con deltas y consolidaciÃ³n
- [x] Seguridad Robusta (HMAC + SerializaciÃ³n Segura)
- [x] Ãrboles Merkle
- [x] OptimizaciÃ³n de rendimiento y memoria

### ğŸš§ **Fase 2 â€“ AceleraciÃ³n HW (Q2 2025)**
- [ ] Kernels CUDA optimizados
- [ ] Prototipo FPGA
- [ ] CachÃ© NVMe inteligente
- [ ] AceleraciÃ³n GPU masiva
- [ ] IntegraciÃ³n con TensorRT

### ğŸ”® **Fase 3 â€“ Silicio (Q4 2025)**
- [ ] DiseÃ±o de MMU-MNEME
- [ ] Tape-out ASIC
- [ ] IntegraciÃ³n en OS
- [ ] Hardware security module
- [ ] Red neuronal dedicada

## ğŸ‘¥ Autores

**Esraderey** y **Raul Cruz Acosta**

## ğŸ“š CitaciÃ³n

```bibtex
@software{mneme2025,
  title = {MNEME: Motor de Memoria Neural MÃ³rfica},
  author = {Esraderey and Raul Cruz Acosta},
  year = {2025},
  url = {https://github.com/esraderey/MNEME---Motor-de-Memoria-Neural-M-rfica},
  note = {Sistema avanzado de memoria computacional con sÃ­ntesis determinista}
}
```

## ğŸ”— Proyectos Relacionados

- **TensorLy** - DescomposiciÃ³n de tensores
- **PyTorch** - Framework de deep learning

## ğŸ’¡ FilosofÃ­a

*"La mejor compresiÃ³n no es guardar los datos, sino guardar la receta para recrearlos."*

*"La memoria no es un archivo estÃ¡tico, sino un organismo vivo que se regenera con cada evocaciÃ³n."*

## ğŸ“ Licencia

Business Source License 1.1 (BUSL-1.1) â€“ ver [LICENSE](LICENSE)

**Nota importante**: Esta licencia incluye restricciones comerciales hasta 2029, despuÃ©s de lo cual se convierte en GPL v2+.

## ğŸ“§ Contacto

- **Issues**: [GitHub Issues](https://github.com/esraderey/MNEME---Motor-de-Memoria-Neural-M-rfica/issues)
- **Discussions**: [GitHub Discussions](https://github.com/esraderey/MNEME---Motor-de-Memoria-Neural-M-rfica/discussions)
- **Email**: msc.framework@gmail.com
- **DocumentaciÃ³n**: [Wiki](https://github.com/esraderey/MNEME---Motor-de-Memoria-Neural-M-rfica/wiki)

## ğŸ† Reconocimientos

- Inspirado en la neurociencia computacional
- Basado en principios de compresiÃ³n de informaciÃ³n
- Influenciado por sistemas de memoria biolÃ³gica
- DiseÃ±ado para eficiencia energÃ©tica

---

*"La memoria no es un archivo estÃ¡tico, sino un organismo vivo que se regenera con cada evocaciÃ³n."* â€“ Esraderey y Raul Cruz Acosta
