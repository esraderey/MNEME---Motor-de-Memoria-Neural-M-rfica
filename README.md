# ğŸ§  MNEME â€“ Motor de Memoria Neural MÃ³rfica

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch 2.0+](https://img.shields.io/badge/PyTorch-2.0+-ee4c2c.svg)](https://pytorch.org/)
[![License: BUSL-1.1](https://img.shields.io/badge/License-BUSL--1.1-blue.svg)](https://opensource.org/licenses/BUSL-1.1)
[![Security](https://img.shields.io/badge/Security-Enterprise-green.svg)](https://github.com/yourusername/mneme)
[![Performance](https://img.shields.io/badge/Performance-Optimized-orange.svg)](https://github.com/yourusername/mneme)

**MNEME** (pronunciado *"neme"*) redefine la memoria computacional mediante un motor neural inspirado en estructuras biolÃ³gicas.  
En lugar de almacenar datos en ubicaciones fijas, **MNEME guarda descriptores compactos y generativos** que reconstruyen el contenido de forma determinista, como si fueran recuerdos que emergen bajo demanda.

---

## ğŸ“‹ Nombre del Proyecto

**MNEME**

- **M**emoria  
- **N**eural  
- **E**structurada  
- **M**Ã³rfica  
- **E**mergente  

---

## ğŸš€ InnovaciÃ³n Clave

Tradicional: **DirecciÃ³n â†’ LocalizaciÃ³n â†’ Datos**  
MNEME: **Descriptor â†’ SÃ­ntesis â†’ Recuerdo**

```python
# Tradicional: Guardar tensor de 4MB en RAM
memory[0x1000] = huge_tensor  

# MNEME: Guardar descriptor de 40KB
descriptor = mneme.store(huge_tensor)  
tensor = mneme.synthesize(descriptor)  # ReconstrucciÃ³n determinista
```

## ğŸ¯ Â¿Por quÃ© MNEME?

ğŸ”¹ **10â€“100x reducciÃ³n de memoria** para modelos ML, imÃ¡genes y estados de simulaciÃ³n

ğŸ”¹ **SÃ­ntesis determinista** â€“ mismo descriptor, mismo resultado

ğŸ”¹ **VerificaciÃ³n criptogrÃ¡fica** â€“ pruebas de integridad en cada operaciÃ³n

ğŸ”¹ **Control de versiones incorporado** â€“ seguimiento con Ã¡rboles de Merkle

ğŸ”¹ **Eficiencia energÃ©tica** â€“ minimiza el movimiento de datos siguiendo el principio de Landauer

ğŸ”¹ **Seguridad empresarial** â€“ auditorÃ­a completa y control de acceso

ğŸ”¹ **OptimizaciÃ³n automÃ¡tica** â€“ gestiÃ³n inteligente de memoria y rendimiento

## ğŸ“Š MÃ©tricas de Rendimiento

| MÃ©trica | Rendimiento |
|---------|-------------|
| Ratio de compresiÃ³n | 10â€“20x en transformadores |
| Latencia de sÃ­ntesis | <150Î¼s (256KB tiles) |
| Latencia de cachÃ© | <1Î¼s |
| PÃ©rdida de calidad | <1% en inferencia ML |
| Ahorro de memoria | 90â€“95% en modelos grandes |
| VerificaciÃ³n criptogrÃ¡fica | <10Î¼s por operaciÃ³n |
| Throughput paralelo | 8x aceleraciÃ³n con 8 cores |

## ğŸ› ï¸ InstalaciÃ³n

### Requisitos

- Python 3.8+
- PyTorch 2.0+
- RAM: mÃ­nimo 4GB (recomendado 8GB)
- Linux / macOS / Windows

### InstalaciÃ³n bÃ¡sica

```bash
pip install mneme
```

### InstalaciÃ³n completa con todas las funcionalidades

```bash
git clone https://github.com/yourusername/mneme.git
cd mneme
pip install -r requirements.txt
pip install -e .[all]
```

### InstalaciÃ³n con optimizaciones

```bash
# Para desarrollo
pip install -e .[dev]

# Para GPU
pip install -e .[gpu]

# Para seguridad empresarial
pip install -e .[security]

# Para optimizaciÃ³n mÃ¡xima
pip install -e .[optimization]
```

## ğŸš¦ Uso RÃ¡pido

### Guardar y recuperar tensores

```python
import torch
from mneme_core import ZSpace

# Inicializar con configuraciÃ³n avanzada
mneme = ZSpace(
    cache_size=1 << 30,  # 1GB
    compression_level=CompressionLevel.HIGH,
    enable_merkle=True,
    enable_checksums=True
)

tensor = torch.randn(1024, 1024)
desc = mneme.register("mi_tensor", tensor, target_ratio=0.1)

# Recuperar
loaded = mneme.load("mi_tensor")
assert torch.allclose(tensor, loaded, rtol=1e-5)
```

### CompresiÃ³n de modelos PyTorch

```python
import torch.nn as nn
from mneme_torch import compress_model, get_compression_stats, CompressionConfig

# ConfiguraciÃ³n de compresiÃ³n
config = CompressionConfig(
    target_ratio=0.1,
    compression_level=CompressionLevel.HIGH,
    memory_limit=50 * 1024 * 1024  # 50MB
)

model = nn.Sequential(
    nn.Linear(784, 512), nn.ReLU(),
    nn.Linear(512, 256), nn.ReLU(),
    nn.Linear(256, 10)
)

compressed = compress_model(model, config=config)
stats = get_compression_stats(compressed)
print(f"CompresiÃ³n lograda: {stats['overall_ratio']:.1%}")
```

### Capas MNEME transparentes

```python
from mneme_torch import ZLinear, ZConv2d, ZAttention, ZTransformerBlock

# Reemplazo directo de capas PyTorch
model = nn.Sequential(
    ZLinear(784, 512, config=CompressionConfig(target_ratio=0.1)),
    nn.ReLU(),
    ZLinear(512, 256, config=CompressionConfig(target_ratio=0.05)),
    nn.ReLU(),
    ZLinear(256, 10, config=CompressionConfig(target_ratio=0.2))
)

# Transformer con compresiÃ³n
transformer = ZTransformerBlock(
    embed_dim=512, 
    num_heads=8, 
    config=CompressionConfig(target_ratio=0.1)
)
```

### Seguridad empresarial

```python
from mneme_security import SecurityManager, SecurityLevel

# Configurar seguridad
security_manager = SecurityManager(
    security_level=SecurityLevel.HIGH,
    audit_log_file="mneme_audit.log"
)

# Crear descriptor seguro
data = torch.randn(100, 100).numpy().tobytes()
secure_desc = security_manager.create_secure_descriptor(data, "sensitive_data")

# Verificar integridad
integrity_ok = secure_desc.verify_integrity()
signature_ok = secure_desc.verify_signature()
```

### OptimizaciÃ³n de rendimiento

```python
from mneme_optimization import MNEMEOptimizer, OptimizationLevel

# Configurar optimizador
optimizer = MNEMEOptimizer(
    max_memory_mb=1024,
    optimization_level=OptimizationLevel.MAXIMUM,
    enable_profiling=True,
    enable_parallel_processing=True
)

# Optimizar operaciones
tensors = [torch.randn(100, 100) for _ in range(10)]
optimized = optimizer.optimize_tensor_operations(tensors)

# Obtener reporte de rendimiento
report = optimizer.get_optimization_report()
```

## ğŸ—ï¸ Arquitectura Avanzada

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        MNEME Core                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Z-Addr (Hashing)   â”‚   Z-Gen (Synthesis)   â”‚   Security       â”‚
â”‚  Cache (LRU+)       â”‚   Proof (Merkle)      â”‚   Auditor        â”‚
â”‚  Prefetch (Markov)  â”‚   Optimization        â”‚   Crypto         â”‚
â”‚---------------------------------------------------------------â”‚
â”‚  Motores de DescomposiciÃ³n: TT | CP | Tucker | SVD | Quantized  â”‚
â”‚  + CompresiÃ³n reversible (LZ4) + VerificaciÃ³n criptogrÃ¡fica    â”‚
â”‚  + GestiÃ³n de memoria + Procesamiento paralelo                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Flujo de datos mejorado

- **Store** â†’ Tensor â†’ Analyze â†’ Decompose â†’ Compress â†’ Encrypt â†’ Descriptor
- **Load** â†’ Descriptor â†’ Decrypt â†’ Decompress â†’ Reconstruct â†’ Verify â†’ Tensor
- **Update** â†’ Delta â†’ Compress â†’ Append chain â†’ New version â†’ Audit
- **Security** â†’ Verify â†’ Audit â†’ Monitor â†’ Report

## ğŸ“ˆ Benchmarks Avanzados

### CompresiÃ³n de Modelos

**Transformer de 6 capas (GPT-2 Small)**
- ParÃ¡metros base: 6,299,648
- MNEME: 503,971 (12.5x compresiÃ³n)
- Uso de memoria: â€“91%
- PÃ©rdida de precisiÃ³n: <0.5%
- Tiempo de inferencia: +15% (aceptable)

**ResNet-50**
- ParÃ¡metros base: 25,557,032
- MNEME: 2,555,703 (10x compresiÃ³n)
- Uso de memoria: â€“90%
- PÃ©rdida de precisiÃ³n: <0.3%

### Rendimiento de Seguridad

- VerificaciÃ³n HMAC: <10Î¼s
- VerificaciÃ³n Merkle: <50Î¼s
- AuditorÃ­a de eventos: <1Î¼s
- Cifrado/descifrado: <100Î¼s

## ğŸ”¬ Funcionalidades Avanzadas

### ğŸ§  **NÃºcleo Inteligente**
- **SelecciÃ³n automÃ¡tica** de descomposiciÃ³n basada en propiedades del tensor
- **Prefetching adaptativo** con aprendizaje Markov de 2do orden
- **GestiÃ³n de memoria inteligente** con monitoreo de presiÃ³n
- **Cache optimizado** con polÃ­ticas LRU adaptativas
- **Procesamiento paralelo** para operaciones masivas

### ğŸ”’ **Seguridad Empresarial**
- **VerificaciÃ³n criptogrÃ¡fica** con HMAC y checksums
- **Ãrboles Merkle** para pruebas de integridad
- **AuditorÃ­a completa** con logging detallado
- **Control de acceso** con bloqueo de recursos
- **MÃºltiples niveles** de seguridad (BASIC â†’ MAXIMUM)

### âš¡ **OptimizaciÃ³n de Rendimiento**
- **Profiler integrado** con mÃ©tricas detalladas
- **GestiÃ³n automÃ¡tica** de memoria y GC
- **Predictor de acceso** con patrones inteligentes
- **OptimizaciÃ³n de tensores** con mÃºltiples niveles
- **Monitoreo en tiempo real** de recursos

### ğŸ”— **IntegraciÃ³n PyTorch**
- **Drop-in replacement** para capas estÃ¡ndar
- **CompresiÃ³n transparente** de modelos existentes
- **Soporte completo** para Transformer, CNN, RNN
- **ConfiguraciÃ³n flexible** por capa
- **EstadÃ­sticas de rendimiento** en tiempo real

## ğŸ® Aplicaciones

### **Machine Learning**
- CompresiÃ³n y serving de modelos LLM
- Entrenamiento distribuido eficiente
- Inferencia en dispositivos edge
- OptimizaciÃ³n de memoria en GPU

### **Simulaciones y Juegos**
- Mundos de juego infinitos y ligeros
- Estados de simulaciÃ³n masivos
- FÃ­sica en tiempo real
- Procedural generation

### **Ciencia de Datos**
- AnÃ¡lisis de datasets masivos
- CompresiÃ³n de matrices dispersas
- CÃ¡lculos cientÃ­ficos optimizados
- VisualizaciÃ³n de datos grandes

### **Seguridad y AuditorÃ­a**
- Sistemas de logging seguros
- VerificaciÃ³n de integridad
- Trazabilidad de datos
- Compliance empresarial

## ğŸ—ºï¸ Roadmap

### âœ… **Fase 1 â€“ NÃºcleo Completo**
- [x] DescomposiciÃ³n avanzada (TT, CP, Tucker, SVD, Quantized)
- [x] IntegraciÃ³n completa con PyTorch
- [x] Sistema de versiones con deltas
- [x] VerificaciÃ³n criptogrÃ¡fica
- [x] Ãrboles Merkle
- [x] AuditorÃ­a de seguridad
- [x] OptimizaciÃ³n de rendimiento

### ğŸš§ **Fase 2 â€“ AceleraciÃ³n HW (Q2 2025)**
- [ ] Kernels CUDA optimizados
- [ ] Prototipo FPGA
- [ ] CachÃ© NVMe inteligente
- [ ] AceleraciÃ³n GPU masiva
- [ ] IntegraciÃ³n con TensorRT

### ğŸ”® **Fase 3 â€“ Silicio (Q4 2025)**
- [ ] DiseÃ±o de MMU-MNEME
- [ ] Tape-out ASIC
- [ ] IntegraciÃ³n en OS
- [ ] Hardware security module
- [ ] Red neuronal dedicada

## ğŸ‘¥ Autores

**Esraderey** y **Raul Cruz Acosta**

## ğŸ“š CitaciÃ³n

```bibtex
@software{mneme2025,
  title = {MNEME: Motor de Memoria Neural MÃ³rfica},
  author = {Esraderey and Raul Cruz Acosta},
  year = {2025},
  url = https://github.com/esraderey/MNEME---Motor-de-Memoria-Neural-M-rfica,
  note = {Sistema avanzado de memoria computacional con sÃ­ntesis determinista}
}
```

## ğŸ”— Proyectos Relacionados
- **TensorLy** - DescomposiciÃ³n de tensores
- **PyTorch** - Framework de deep learning

## ğŸ’¡ FilosofÃ­a

*"La mejor compresiÃ³n no es guardar los datos, sino guardar la receta para recrearlos."*

*"La memoria no es un archivo estÃ¡tico, sino un organismo vivo que se regenera con cada evocaciÃ³n."*

## ğŸ“ Licencia

Business Source License 1.1 (BUSL-1.1) â€“ ver [LICENSE](LICENSE)

**Nota importante**: Esta licencia incluye restricciones comerciales hasta 2029, despuÃ©s de lo cual se convierte en GPL v2+.

## ğŸ“§ Contacto

- **Issues**: [GitHub Issues](https://github.com/yourusername/mneme/issues)
- **Discussions**: [GitHub Discussions](https://github.com/yourusername/mneme/discussions)
- **Email**: msc.framework@gmail.com
- **DocumentaciÃ³n**: [Wiki]
https://github.com/esraderey/MNEME---Motor-de-Memoria-Neural-M-rfica

## ğŸ† Reconocimientos

- Inspirado en la neurociencia computacional
- Basado en principios de compresiÃ³n de informaciÃ³n
- Influenciado por sistemas de memoria biolÃ³gica
- DiseÃ±ado para eficiencia energÃ©tica

---

*"La memoria no es un archivo estÃ¡tico, sino un organismo vivo que se regenera con cada evocaciÃ³n."* â€“ Esraderey y Raul Cruz Acosta
